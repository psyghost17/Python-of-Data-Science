{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Header](images/01/packt publishing.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Raw Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the world of data science, raw data comes in many forms and sizes. There is a\n",
    "lot of information that can be extracted from this raw data. To give an example,\n",
    "Amazon collects click stream data that records each and every click of the user on the\n",
    "website. This data can be utilized to understand if a user is a price-sensitive customer\n",
    "or prefer more popularly rated products. You must have noticed recommended\n",
    "products in Amazon; they are derived using such data.\n",
    "The first step towards such an analysis would be to parse raw data. The parsing of\n",
    "the data involves the following steps:\n",
    "* Extracting data from the source: Data can come in many forms, such as Excel, CSV, JSON, databases, and so on. Python makes it very easy to read data from these sources with the help of some useful packages, which will be covered in this chapter.\n",
    "* Cleaning the data: Once a sanity check has been done, one needs to clean the data appropriately so that it can be utilized for analysis. You may have a dataset about students of a class and details about their height, weight, and marks. There may also be certain rows with the height or weight missing. Depending on the analysis being performed, these rows with missing values can either be ignored or replaced with the average height or weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter we will cover the following topics:\n",
    "\n",
    "* Exploring arrays with NumPy\n",
    "* Handling data with pandas\n",
    "* Reading and writing data from various formats\n",
    "* Handling missing data\n",
    "* Manipulating data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The world of arrays with NumPy\n",
    "Python, by default, comes with a data structure, such as List, which can be utilized\n",
    "for array operations, but a Python list on its own is not suitable to perform heavy\n",
    "mathematical operations, as it is not optimized for it.\n",
    "NumPy is a wonderful Python package produced by Travis Oliphant, which\n",
    "has been created fundamentally for scientific computing. It helps handle large\n",
    "multidimensional arrays and matrices, along with a large library of high-level\n",
    "mathematical functions to operate on these arrays.\n",
    "A NumPy array would require much less memory to store the same amount of data\n",
    "compared to a Python list, which helps in reading and writing from the array in a\n",
    "faster manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an array\n",
    "A list of numbers can be passed to the following array function to create a NumPy\n",
    "array object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "n_array = np.array([[0, 1, 2, 3],\n",
    "[4, 5, 6, 7],\n",
    "[8, 9, 10, 11]])\n",
    "\n",
    "n_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A NumPy array object has a number of attributes, which help in giving information\n",
    "about the array. Here are its important attributes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ndim:** This gives the number of dimensions of the array. The following shows\n",
    "that the array that we defined had two dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_array.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_array has a rank of 2, which is a 2D array.\n",
    "**shape:** This gives the size of each dimension of the array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first dimension of n_array has a size of 3 and the second dimension has\n",
    "a size of 4. This can be also visualized as three rows and four columns.\n",
    "**size:** This gives the number of elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_array.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total number of elements in n_array is 12.\n",
    "**dtype:** This gives the datatype of the elements in the array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'int32'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_array.dtype.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number is stored as int64 in n_array.\n",
    "\n",
    "### Mathematical operations\n",
    "When you have an array of data, you would like to perform certain mathematical\n",
    "operations on it. We will now discuss a few of the important ones in the following\n",
    "sections.\n",
    "\n",
    "### Array subtraction\n",
    "The following commands subtract the a array from the b array to get the resultant\n",
    "c array. The subtraction happens element by element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 10, 10, 10])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array( [11, 12, 13, 14])\n",
    "b = np.array( [ 1, 2, 3, 4])\n",
    "c = a - b\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do note that when you subtract two arrays, they should be of equal dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squaring an array\n",
    "The following command raises each element to the power of 2 to obtain this result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  4,  9, 16])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A trigonometric function performed on the array\n",
    "The following command applies cosine to each of the values in the b array to obtain\n",
    "the following result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.54030231, -0.41614684, -0.9899925 , -0.65364362])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cos(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional operations\n",
    "The following command will apply a conditional operation to each of the elements of\n",
    "the b array, in order to generate the respective Boolean values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False, False], dtype=bool)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b<2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix multiplication\n",
    "Two matrices can be multiplied element by element or in a dot product. The\n",
    "following commands will perform the element-by-element multiplication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1],\n",
       "       [0, 1]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A1 = np.array([[1, 1],\n",
    "[0, 1]])\n",
    "A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A2 = np.array([[2, 0],\n",
    "[3, 4]])\n",
    "A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0],\n",
       "       [0, 4]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A1 * A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 4],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(A1, A2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing and slicing\n",
    "If you want to select a particular element of an array, it can be achieved using indexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_array[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preceding command will select the first array and then select the second value in\n",
    "the array. It can also be seen as an intersection of the first row and the second column\n",
    "of the matrix.\n",
    "If a range of values has to be selected on a row, then we can use the following\n",
    "command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_array[ 0 , 0:3 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The 0:3 value selects the first three values of the first row.\n",
    "The whole row of values can be selected with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_array[ 0 , : ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Using the following command, an entire column of values need to be selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 5, 9])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_array[ : , 1 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Shape manipulation\n",
    "Once the array has been created, we can change the shape of it too. The following\n",
    "command flattens the array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_array.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The following command reshapes the array in to a six rows and two columns format.\n",
    "Also, note that when reshaping, the new shape should have the same number of\n",
    "elements as the previous one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1],\n",
       "       [ 2,  3],\n",
       "       [ 4,  5],\n",
       "       [ 6,  7],\n",
       "       [ 8,  9],\n",
       "       [10, 11]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_array.shape = (6,2)\n",
    "n_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The array can be transposed too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  2,  4,  6,  8, 10],\n",
       "       [ 1,  3,  5,  7,  9, 11]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_array.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Empowering data analysis with pandas\n",
    "The pandas library was developed by Wes McKinny when he was working at\n",
    "AQR Capital Management. He wanted a tool that was flexible enough to perform\n",
    "quantitative analysis on financial data. Later, Chang She joined him and helped\n",
    "develop the package further.\n",
    "The pandas library is an open source Python library, specially designed for data\n",
    "analysis. It has been built on NumPy and makes it easy to handle data. NumPy is a\n",
    "fairly low-level tool that handles matrices really well.\n",
    "The pandas library brings the richness of R in the world of Python to handle data. It's\n",
    "has efficient data structures to process data, perform fast joins, and read data from\n",
    "various sources, to name a few.\n",
    "\n",
    "The data structure of pandas\n",
    "The pandas library essentially has three data structures:\n",
    "1. Series\n",
    "2. DataFrame\n",
    "3. Panel\n",
    "Series\n",
    "Series is a one-dimensional array, which can hold any type of data, such as integers,\n",
    "floats, strings, and Python objects too. A series can be created by calling the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-100fddf36e51>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.Series(np.random.randn(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random.randn parameter is part of the NumPy package and it generates random\n",
    "numbers. The series function creates a pandas series that consists of an index, which\n",
    "is the first column, and the second column consists of random values. At the bottom\n",
    "of the output is the datatype of the series.\n",
    "The index of the series can be customized by calling the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.Series(np.random.randn(5), index=['a', 'b', 'c', 'd', 'e'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A series can be derived from a Python dict too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = {'A': 10, 'B': 20, 'C': 30}\n",
    "pd.Series(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame\n",
    "DataFrame is a 2D data structure with columns that can be of different datatypes. It\n",
    "can be seen as a table. A DataFrame can be formed from the following data structures:\n",
    "* A NumPy array\n",
    "* Lists\n",
    "* Dicts\n",
    "* Series\n",
    "* A 2D NumPy array\n",
    "\n",
    "A DataFrame can be created from a dict of series by calling the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = {'c1': pd.Series(['A', 'B', 'C']),\n",
    "'c2': pd.Series([1, 2., 3., 4.])}\n",
    "df = pd.DataFrame(d)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "The DataFrame can be created using a dict of lists too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print' (<ipython-input-6-ee89cc02fcd2>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-ee89cc02fcd2>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    print df\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m Missing parentheses in call to 'print'\n"
     ]
    }
   ],
   "source": [
    "d= {'c1': ['A', 'B', 'C', 'D'],'c2': [1, 2.0, 3.0, 4.0]}\n",
    "df = pd.DataFrame(d)\n",
    "print df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Panel\n",
    "A Panel is a data structure that handles 3D data. The following command is an\n",
    "example of panel data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-b655876cbfff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m d = {'Item1': pd.DataFrame(np.random.randn(4, 3)),\n\u001b[0m\u001b[0;32m      2\u001b[0m 'Item2': pd.DataFrame(np.random.randn(4, 2))}\n\u001b[0;32m      3\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPanel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "d = {'Item1': pd.DataFrame(np.random.randn(4, 3)),\n",
    "'Item2': pd.DataFrame(np.random.randn(4, 2))}\n",
    "pd.Panel(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The preceding command shows that there are 2 DataFrames represented by two\n",
    "items. There are four rows represented by four major axes and three columns\n",
    "represented by three minor axes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Inserting and exporting data\n",
    "The data is stored in various forms, such as CSV, TSV, databases, and so on. The\n",
    "pandas library makes it convenient to read data from these formats or to export to\n",
    "these formats. We'll use a dataset that contains the weight statistics of the school\n",
    "students from the U.S..\n",
    "We'll be using a file with the following structure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![Table](images/01/table.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### CSV\n",
    "To read data from a .csv file, the following read_csv function can be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-7-2e0118a82768>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-7-2e0118a82768>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    d = pd.read_csv('Data/Student_Weight_Status_Category_\u001b[0m\n\u001b[1;37m                                                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "d = pd.read_csv('Data/Student_Weight_Status_Category_\n",
    "Reporting_Results__Beginning_2010.csv')\n",
    "d[0:5]['AREA NAME']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The read_csv function takes the path of the .csv file to input the data. The\n",
    "command after this prints the first five rows of the Location column in the data.\n",
    "To write a data to the .csv file, the following to_csv function can be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = {'c1': pd.Series(['A', 'B', 'C']),\n",
    "'c2': pd.Series([1, 2., 3., 4.])}\n",
    "df = pd.DataFrame(d)\n",
    "df.to_csv('sample_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The DataFrame is written to a .csv file by using the to_csv method. The path and\n",
    "the filename where the file needs to be created should be mentioned.\n",
    "\n",
    "### XLS\n",
    "In addition to the pandas package, the xlrd package needs to be installed for pandas\n",
    "to read the data from an Excel file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d=pd.read_excel('Data/Student_Weight_Status_Category\n",
    "_Reporting_Results__Beginning_2010.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The preceding function is similar to the CSV reading command. To write to an Excel\n",
    "file, the xlwt package needs to be installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_excel('sample_data.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### JSON\n",
    "To read the data from a JSON file, Python's standard json package can be used. The\n",
    "following commands help in reading the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "json_data = open('Data/Student_Weight_Status_Category\n",
    "_Reporting_Results__Beginning_2010.json')\n",
    "data = json.load(json_data)\n",
    "json_data.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the preceding command, the open() function opens a connection to the file. The\n",
    "json.load() function loads the data into Python. The json_data.close() function\n",
    "closes the connection to the file.\n",
    "The pandas library also provides a function to read the JSON file, which can be\n",
    "accessed using pd.read_json().\n",
    "\n",
    "### Database\n",
    "To read data from a database, the following function can be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.read_sql_table(table_name, con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preceding command generates a DataFrame. If a table name and an SQLAlchemy\n",
    "engine are given, they return a DataFrame. This function does not support the DBAPI\n",
    "connection. The following are the description of the parameters used:\n",
    "* table_name: This refers to the name of the SQL table in a database\n",
    "* con: This refers to the SQLAlchemy engine\n",
    "The following command reads SQL query into a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.read_sql_query(sql, con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are the description of the parameters used:\n",
    "• sql: This refers to the SQL query that is to be executed\n",
    "• con: This refers to the SQLAlchemy engine\n",
    "    \n",
    "### Data cleansing\n",
    "The data in its raw form generally requires some cleaning so that it can be analyzed\n",
    "or a dashboard can be created on it. There are many reasons that data might\n",
    "have issues. For example, the Point of Sale system at a retail shop might have\n",
    "malfunctioned and inputted some data with missing values. We'll be learning\n",
    "how to handle such data in the following section.  \n",
    "\n",
    "### Checking the missing data\n",
    "Generally, most data will have some missing values. There could be various reasons\n",
    "for this: the source system which collects the data might not have collected the values\n",
    "or the values may never have existed. Once you have the data loaded, it is essential\n",
    "to check the missing elements in the data. Depending on the requirements, the\n",
    "missing data needs to be handled. It can be handled by removing a row or replacing\n",
    "a missing value with an alternative value.\n",
    "In the Student Weight data, to check if the location column has missing value,\n",
    "the following command can be utilized:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d['Location 1'].isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notnull() method will output each row of the value as TRUE or FALSE. If it's\n",
    "False, then there is a missing value. This data can be aggregated to find the number\n",
    "of instances of the missing value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d['Location 1'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preceding command shows that the Location 1 column has 24 instances of\n",
    "missing values. These missing values can be handled by either removing the rows\n",
    "with the missing values or replacing it with some values. To remove the rows,\n",
    "execute the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = d['Location 1'].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To remove all the rows with an instance of missing values, use the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = d.dropna(how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling the missing data\n",
    "Let's define some DataFrames to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(5, 3), index=['a0', 'a10',\n",
    "'a20', 'a30', 'a40'],\n",
    "columns=['X', 'Y', 'Z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now add some extra row indexes, which will create null values in our DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = df2.reindex(['a0', 'a1', 'a10', 'a11', 'a20', 'a21',\n",
    "'a30', 'a31', 'a40', 'a41'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to replace the null values in the df2 DataFrame with a value of zero in\n",
    "the following case, execute the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to fill the value with forward propagation, which means that the\n",
    "value previous to the null value in the column will be used to fill the null value,\n",
    "the following command can be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2.fillna(method='pad') #filling with forward propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to fill the null values of the column with the column mean, then the\n",
    "following command can be utilized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2.fillna(df2.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### String operations\n",
    "Sometimes, you would want to modify the string field column in your data.\n",
    "The following technique explains some of the string operations:\n",
    "• Substring: Let's start by choosing the first five rows of the AREA NAME\n",
    "column in the data as our sample data to modify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/Student_Weight_Status_Category_\n",
    "Reporting_Results__Beginning_2010.csv')\n",
    "df['AREA NAME'][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In order to extract the first word from the Area Name column, we'll use the\n",
    "extract function as shown in the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['AREA NAME'][0:5].str.extract('(\\w+)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the preceding command, the str attribute of the series is utilized. The str\n",
    "class contains an extract method, where a regular expression could be fed\n",
    "to extract data, which is very powerful. It is also possible to extract a second\n",
    "word in AREA NAME as a separate column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['AREA NAME'][0:5].str.extract('(\\w+)\\s(\\w+)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract data in different columns, the respective regular expression needs\n",
    "to be enclosed in separate parentheses.\n",
    "* Filtering: If we want to filter rows with data on ELEMENTARY school, then the following command can be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[df['GRADE LEVEL'] == 'ELEMENTARY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Uppercase: To convert the area name to uppercase, we'll use the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['AREA NAME'][0:5].str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data strings are in uppercase already, there won't be any\n",
    "difference seen.\n",
    "\n",
    "* Lowercase: To convert Area Name to lowercase, we'll use the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['AREA NAME'][0:5].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Length: To find the length of each element of the Area Name column, we'll use the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['AREA NAME'][0:5].str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Split: To split Area Name based on a whitespace, we'll use the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['AREA NAME'][0:5].str.split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Replace: If we want to replace all the area names ending with DISTRICT to DIST, then the following command can be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['AREA NAME'][0:5].str.replace('DISTRICT$', 'DIST')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first argument in the replace method is the regular expression used to\n",
    "identify the portion of the string to replace. The second argument is the value\n",
    "for it to be replaced with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging data\n",
    "To combine datasets together, the concat function of pandas can be utilized.\n",
    "Let's take the Area Name and the County columns with its first five rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d[['AREA NAME', 'COUNTY']][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can divide the data as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p1 = d[['AREA NAME', 'COUNTY']][0:2]\n",
    "p2 = d[['AREA NAME', 'COUNTY']][2:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first two rows of the data are in p1 and the last three rows are in p2. These pieces\n",
    "can be combined using the concat() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.concat([p1,p2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The combined pieces can be identified by assigning a key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "concatenated = pd.concat([p1,p2], keys = ['p1','p2'])\n",
    "concatenated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the keys, the pieces can be extracted back from the concatenated data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "concatenated.ix['p1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data operations\n",
    "Once the missing data is handled, various operations can be performed on the data.\n",
    "\n",
    "### Aggregation operations\n",
    "There are a number of aggregation operations, such as average, sum, and so on,\n",
    "which you would like to perform on a numerical field. These are the methods\n",
    "used to perform it:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Average: To find out the average number of students in the ELEMENTARY\n",
    "school who are obese, we'll first filter the ELEMENTARY data with the\n",
    "following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = d[d['GRADE LEVEL'] == 'ELEMENTARY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll find the mean using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['NO. OBESE'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The elementary grade level data is filtered and stored in the data object. The\n",
    "NO. OBESE column is selected, which contains the number of obese students\n",
    "and using the mean() method, the average is taken out.\n",
    "\n",
    "**SUM:** To find out the total number of elementary students who are obese\n",
    "across all the school, use the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['NO. OBESE'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MAX:** To get the maximum number of students that are obese in an\n",
    "elementary school, use the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['NO. OBESE'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MIN:** To get the minimum number of students that are obese in an\n",
    "elementary school, use the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['NO. OBESE'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STD:** To get the standard deviation of the number of obese students, use the\n",
    "following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['NO. OBESE'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COUNT:** To count the total number of schools with the ELEMENTARY grade in\n",
    "the DELAWARE county, use the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = df[(d['GRADE LEVEL'] == 'ELEMENTARY') &\n",
    "(d['COUNTY'] == 'DELAWARE')]\n",
    "data['COUNTY'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table is filtered for the ELEMENTARY grade and the DELAWARE county.\n",
    "Notice that the conditions are enclosed in parentheses. This is to ensure that\n",
    "individual conditions are evaluated and if the parentheses are not provided,\n",
    "then Python will throw an error.\n",
    "\n",
    "### Joins\n",
    "SQL-like joins can be performed on the DataFrame using pandas. Let's define\n",
    "a lookup DataFrame, which assigns levels to each of the grades using the\n",
    "following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grade_lookup = {'GRADE LEVEL': pd.Series(['ELEMENTARY',\n",
    "'MIDDLE/HIGH', 'MISC']),\n",
    "'LEVEL': pd.Series([1, 2, 3])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grade_lookup = DataFrame(grade_lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take the first five rows of the GRADE data column as an example for performing\n",
    "the joins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[['GRADE LEVEL']][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The inner join\n",
    "The following image is a sample of an inner join:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Set 1](images/01/set_1.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An inner join can be performed with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_sub = df[0:5].join(grade_lookup.set_index(['GRADE LEVEL']),\n",
    "on=['GRADE LEVEL'], how='inner')\n",
    "d_sub[['GRADE LEVEL', 'LEVEL']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The join takes place with the join() method. The first argument takes the\n",
    "DataFrame on which the lookup takes place. Note that the grade_lookup\n",
    "DataFrame's index is being set by the set_index() method. This is essential\n",
    "for a join, as without it, the join method won't know on which column to join\n",
    "the DataFrame to.\n",
    "The second argument takes a column of the d DataFrame to join the data. The third\n",
    "argument defines the join as an inner join.\n",
    "\n",
    "### The left outer join\n",
    "The following image is a sample of a left outer join:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![Set 2](images/01/set_2.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A left outer join can be performed with the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_sub = df[0:5].join(grade_lookup.set_index(['GRADE LEVEL']),\n",
    "on=['GRADE LEVEL'], how='left')\n",
    "d_sub[['GRADE LEVEL', 'LEVEL']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can notice that **DISTRICT TOTAL** has missing values for a level column, as the\n",
    "grade_lookup DataFrame does not have an instance for **DISTRICT TOTAL**.\n",
    "\n",
    "### The full outer join\n",
    "The following image is a sample of a full outer join:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![Set 3](images/01/set_3.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full outer join can be performed with the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_sub = df[0:5].join(grade_lookup.set_index(['GRADE LEVEL']),\n",
    "on=['GRADE LEVEL'], how='outer')\n",
    "d_sub[['GRADE LEVEL', 'LEVEL']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The groupby function\n",
    "It's easy to do an SQL-like group by operation with pandas. Let's say, if you want to\n",
    "find the sum of the number of obese students in each of the grades, then you can use\n",
    "the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['NO. OBESE'].groupby(d['GRADE LEVEL']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command chooses the number of obese students column, then uses the group\n",
    "by method to group the data-based group level, and finally, the sum method sums\n",
    "up the number. The same can be achieved by the following function too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d['NO. OBESE'].groupby(d['GRADE LEVEL']).aggregate(sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the aggregate method is utilized. The sum function is passed to obtain the\n",
    "required results.\n",
    "It's also possible to obtain multiple kinds of aggregations on the same metric.\n",
    "This can be achieved by the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['NO. OBESE'].groupby(d['GRADE LEVEL']).aggregate([sum, mean,\n",
    "std])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "In this chapter, we got familiarized with the NumPy and pandas packages. We\n",
    "understood the different datatypes in pandas and how to utilize them. We learned\n",
    "how to perform data cleansing and manipulation, in which we handled missing values\n",
    "and performed string operations. This chapter gives us a foundation for data science\n",
    "and you can dive deeper into NumPy and pandas by clicking on the following links:\n",
    "* NumPy documentation: http://docs.scipy.org/doc/\n",
    "* pandas documentation: http://pandas.pydata.org/\n",
    "In the next chapter, we'll learn about the meaning of inferential statistics and what\n",
    "they do, and also how to make sense of the different concepts in inferential statistics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
